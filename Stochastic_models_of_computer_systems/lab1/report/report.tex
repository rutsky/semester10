% Report.
%
% Copyright (C) 2011  Vladimir Rutsky <altsysrq@gmail.com>
%
% This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 
% Unported License. See <http://creativecommons.org/licenses/by-sa/3.0/> 
% for details.

\documentclass[a4paper,10pt]{article}

% Encoding support.
\usepackage{ucs}
\usepackage[utf8x]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}

\usepackage{amsmath, amsthm, amssymb}

% Indenting first paragraph.
\usepackage{indentfirst}

\usepackage{url}
\usepackage[unicode]{hyperref}

%\usepackage[final]{pdfpages}

\usepackage[pdftex]{graphicx}
\usepackage{subfig}

\usepackage{fancyvrb}
\usepackage{color}
\usepackage{texments}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

% Spaces after commas.
\frenchspacing
% Minimal carrying number of characters,
\righthyphenmin=2

% From K.V.Voroncov Latex in samples, 2005.
\textheight=24cm   % text height
\textwidth=16cm    % text width.
\oddsidemargin=0pt % left side indention
\topmargin=-1.5cm  % top side indention.
\parindent=24pt    % paragraph indent
\parskip=0pt       % distance between paragraphs.
\tolerance=2000
%\flushbottom       % page height aligning
%\hoffset=0cm
%\pagestyle{empty}  % without numeration

\newcommand{\myemail}[1]{%
\href{mailto:#1}{\nolinkurl{#1}}}

\newcommand{\myfunc}[1]{%
\textit{#1}}

\begin{document}

% Title page.
\input{./title.tex}
%\tableofcontents
%\pagebreak

% Content

\section{Постановка задачи}
Дан упорядоченный набор кодов:
$$M' = (s_0', \ldots, s_n'), \quad s_i' \in \Sigma', \quad \Sigma' = \{ c_0', \ldots, c_k' \},$$
где $c_i'$~--- коды из алфавита $\Sigma'$.
Необходимо проверить гипотезу о том, что в сообщении закодировано сообщение 
на английском языке
$$M = (s_0, \ldots, s_n), \quad s_i \in \Sigma, \quad \Sigma = \{ c_0, \ldots, c_k \},$$
где $c_i$~--- буквы английского алфавита и разделители, 
при условии, что кодирование было произведено 
переобозначением с помощью некоторой биекции 
$g \colon \Sigma \rightarrow \Sigma'$ 
исходных символов кодами: 
$$M' = g(M) \stackrel{\rm def}{=} \left (g(s_0), \ldots, g(s_n) \right).$$

\section{Решение}
Основная идея решения поставленной задачи состоит в следующем: 
\begin{enumerate}
  \item переберём все биекции
  $$g_j \in G = \left \{ g \colon \Sigma \rightarrow \Sigma' \right \},$$ 
  \item для каждой $g_j$ <<декодируем>> сообщение: 
  $$M^{*}_j = g^{-1}(M') = (s_{j0}^{*}, \ldots, s_{jn}^{*}),$$
  \item проверим насколько полученное сообщение $M^{*}_j$ <<похоже>> на 
  английский текст.
\end{enumerate}
Если найдутся биекции для которых декодированное сообщение похоже на английский
язык, то ответ на поставленный вопрос будет положительным, 
иначе~--- отрицательным.

Проверка соответствия декодированного сообщения английскому языку проводится
исходя из двух грубых моделей текстов на английском языке.

\subsection{Модель независимых символов}
\label{chi2}
%TODO: Добавить (\Omega, A, P)
Текст на английском языке из $n$ символов $M = (s_0, \ldots, s_n)$
можно представить как $n$ наблюдений некоторой дискретной случайной
величины $\xi_{\rm eng},$ принимающая значения из $\Sigma$ 
с некоторыми вероятностями 
$\bar{p}^\circ = (p_1^{\circ}, \ldots, p_k^{\circ}), \quad
p_1^{\circ} + \ldots + p_k^{\circ} = 1$.

Предположим, что в $M'$ закодировано сообщение на английском языке.
Тогда для выбранной биекции $g_j$ каждый символ декодированного сообщения 
$M_j^{*} = (s_{j0}^{*}, \ldots, s_{jn}^{*})$%
~--- это независимое наблюдение некоторой дискретной случайной 
величины $\xi$, принимающей значения из $\Sigma$
с вероятностями $\bar{p} = (p_1, \ldots, p_k), \quad p_1 + \ldots + p_k = 1$,
а проверяемая гипотеза $H_0$ будет состоять в том, что $\xi = \xi_{\rm eng},$
т.\,е.~$\bar{p} = \bar{p}^{\circ}.$

Рассмотрим случайную величину
$$\nu_i = \sum\limits_{t=1}^{n} I(s_{jt}^{*} = c_i), \quad i=1,\ldots,k,$$
--- частоты различных исходов наблюдений ($\nu_1+\ldots+\nu_k=n$).
Вектор $\bar{\nu} = (\nu_1, \ldots, \nu_k)$ 
имеет полиномиальное распределение $M(n; p_1, \ldots, p_k).$
Эффективной оценкой $\bar{p}$ по методу
максимального правдоподобия является $\bar{\nu} / n$.%
%\footnote{\S\,3.2, пример 10 в \cite{ivchmed2010matstat}.}
\footnote{\S\,3.5, пример 12 в \cite{ivchmed2010matstat}.}
Из центральной пределельной теоремы для полиномиального распределения%
\footnote{Упр. 33 к главе 1 в \cite{ivchmed2010matstat}.}
следует, что при $n \rightarrow \infty$ оценка 
$p_i = \nu_i / n$, как случайная величина,
асимптотически обладает нормальным распределением:
$$\mathcal{L}\left(\frac{\nu_i}{n}\right) 
    \stackrel{n \rightarrow \infty}{=} \mathcal{N}(p_i, \sqrt{np_i^\circ}), \quad i=1,\ldots,k.$$
Тогда статистика
$$X_n^2 = \sum\limits_{i=1}^{k} \frac{(\nu_i - np_i^\circ)^2}{np_i^\circ} = 
  \sum\limits_{i=1}^{k} \frac{\nu_i^2}{np_i^\circ} - n$$
асимптотически при $n \rightarrow \infty$ будет обладать распределением $\chi^2.$
Применим к полученной статистике критерий $\chi^2$ Пирсона:
$$H_0\ \mathrm{rejected} \Leftrightarrow 
    \left \{ X_n^2 > \chi_{1-\alpha,n-1}^2 \right \}.$$
В зависимости от того, будет ли отвергнута нулевая гипотеза или нет, будем 
соответственно считать, что декодированное сообщение <<не похоже>> на английский
текст или <<похоже>>.

\subsection{Модель цепи Маркова первого порядка}
% TODO: Дважды стохастическая матрица.
Представим текст на английском языке как траекторию марковского процесса 
первого порядка $X(t)$:
$$\mathbf{P}(x_{t + 1} = y_{t+1} | x_{\tau} = y_\tau, \tau \leqslant t) =
  \mathbf{P}(x_{t + 1} = y_{t+1} | x_t = y_t), 
    \quad y_t \in \Sigma,$$
--- вероятность появления символа в позиции $t+1$ зависит только от того, 
какой символ был в позиции $t$.
Такой марковский процесс задаётся матрицей вероятностей появления символа $j$ 
сразу после символа $i$: $S = (p_{ij})_{i, j = 1}^k.$

Рассмотрим в траектории процесса $X(t)$ все позиции $T \subset \mathbb{N}$, 
где встречается символ $c_i \in \Sigma,$ для фиксированного $i$.
Вероятности появления конкретных символов на следующих позициях 
$\{ t + 1 | t \in T \}$ описываются $i$-й строкой матрицы $S$.%
%TODO: This is incorrect! Probabilities must be normalized first.
Таким образом появление следующего за $c_i$ символа описывается 
некоторой случайной величиной $\xi_{{\rm eng}_i},$ принимающей значения из 
$\Sigma$ с вероятностями $(p_{i1}, \ldots, p_{ik})$.

Для проверки схожести декодированного текста с текстом на английском языке
применим критерий $\chi^2$ Пирсона, описанный в пункте \ref{chi2},
для случайной величины $\xi_{{\rm eng}_i}.$

%Количество биекция даже для небольших величин $n$ велико: $n!$.
%Для сокращения времени перебора оценим 

%\section{Результаты работы}

%\appendix
%\section{Исходный код}
%\label{appendix:sources}

%\usestyle{default}

%\subsection{Title}
%\label{appendix:sources:sources-name}
%\includecode[python -O linenos=1]{data/source.py}

\pagebreak

\bibliographystyle{unsrt}
\bibliography{references}

\end{document}
